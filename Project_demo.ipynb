{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 47,
>>>>>>> 0e9e0707f2ca950a058e4da41c04e5b00e1c42c7
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defs\n",
    "\n",
    "def tokenize(corpus : str) -> list:\n",
    "    tokens = []\n",
    "    for sentence in corpus:\n",
    "        tokens.append(sentence.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(tokens):\n",
    "        vocabulary = []\n",
    "        for sentence in tokens:\n",
    "            for token in sentence:\n",
    "                if token not in vocabulary:\n",
    "                    vocabulary.append(token)\n",
    "        word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}    \n",
    "        return word2idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_word(tokens):\n",
    "        vocabulary = []\n",
    "        for sentence in tokens:\n",
    "            for token in sentence:\n",
    "                if token not in vocabulary:\n",
    "                    vocabulary.append(token)\n",
    "\n",
    "        idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}    \n",
    "        return idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2index(tokens):\n",
    "    vocabulary = []\n",
    "    for sentence in tokens:\n",
    "        for token in sentence:\n",
    "            if token not in vocabulary:\n",
    "                vocabulary.append(token)\n",
    "    word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}    \n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_center_context_pair(tokens, window: int) -> dict:\n",
    "    pairs = dict()\n",
    "    for row in tokens:\n",
    "        for idx, center_word in enumerate(row):\n",
    "            pairs.setdefault(center_word, [])\n",
    "            for i in range(idx - window, idx + window + 1):\n",
    "                if (i >= 0 and i != idx and i < len(row)):\n",
    "                    pairs[center_word].append(row[i])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 51,
>>>>>>> 0e9e0707f2ca950a058e4da41c04e5b00e1c42c7
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jdt(cc_pair: dict) -> list:\n",
    "    jdt = []\n",
    "    for center in cc_pair.keys():\n",
    "        for context in cc_pair[center]:\n",
    "            jdt.append([center, context])\n",
    "    return jdt"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 52,
>>>>>>> 0e9e0707f2ca950a058e4da41c04e5b00e1c42c7
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_p_of_context_given_center(joint_distrib_table: pd.DataFrame):\n",
    "    counts = joint_distrib_table.groupby(['center', 'context']).size()\n",
    "    counts = counts.to_dict()\n",
    "\n",
    "    # Denominator for the probability\n",
    "    total = joint_distrib_table.groupby('center').size()\n",
    "    total = total.to_dict()\n",
    "\n",
    "    for center in total.keys():\n",
    "        for k in list(counts.keys()):\n",
    "            if k[0] is center:\n",
    "                counts[k] = [counts[k]]\n",
    "                counts[k].append(total[center])\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 53,
>>>>>>> 0e9e0707f2ca950a058e4da41c04e5b00e1c42c7
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "        \"he is a king\",\n",
    "        \"she is a queen\",\n",
    "        \"he is a man\",\n",
    "        \"she is a woman\",\n",
    "        \"warsaw is poland capital\",\n",
    "        \"berlin is germany capital\",\n",
    "        \"paris is france capital\",\n",
    "        # \"Sxi este juna kaj bela\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
>>>>>>> 0e9e0707f2ca950a058e4da41c04e5b00e1c42c7
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he is a king',\n",
      " 'she is a queen',\n",
      " 'he is a man',\n",
      " 'she is a woman',\n",
      " 'warsaw is poland capital',\n",
      " 'berlin is germany capital',\n",
      " 'paris is france capital']\n",
      "{'a': ['he',\n",
      "       'is',\n",
      "       'king',\n",
      "       'she',\n",
      "       'is',\n",
      "       'queen',\n",
      "       'he',\n",
      "       'is',\n",
      "       'man',\n",
      "       'she',\n",
      "       'is',\n",
      "       'woman'],\n",
      " 'berlin': ['is', 'germany'],\n",
      " 'capital': ['is', 'poland', 'is', 'germany', 'is', 'france'],\n",
      " 'france': ['paris', 'is', 'capital'],\n",
      " 'germany': ['berlin', 'is', 'capital'],\n",
      " 'he': ['is', 'a', 'is', 'a'],\n",
      " 'is': ['he',\n",
      "        'a',\n",
      "        'king',\n",
      "        'she',\n",
      "        'a',\n",
      "        'queen',\n",
      "        'he',\n",
      "        'a',\n",
      "        'man',\n",
      "        'she',\n",
      "        'a',\n",
      "        'woman',\n",
      "        'warsaw',\n",
      "        'poland',\n",
      "        'capital',\n",
      "        'berlin',\n",
      "        'germany',\n",
      "        'capital',\n",
      "        'paris',\n",
      "        'france',\n",
      "        'capital'],\n",
      " 'king': ['is', 'a'],\n",
      " 'man': ['is', 'a'],\n",
      " 'paris': ['is', 'france'],\n",
      " 'poland': ['warsaw', 'is', 'capital'],\n",
      " 'queen': ['is', 'a'],\n",
      " 'she': ['is', 'a', 'is', 'a'],\n",
      " 'warsaw': ['is', 'poland'],\n",
      " 'woman': ['is', 'a']}\n",
      "Joint Distribution Table\n",
      "  center context\n",
      "0     he      is\n",
      "1     he       a\n",
      "2     he      is\n",
      "3     he       a\n",
      "4     is      he\n",
      "5     is       a\n",
      "6     is    king\n",
      "7     is     she\n",
      "8     is       a\n",
      "9     is   queen\n",
      "{('a', 'he'): [2, 12],\n",
      " ('a', 'is'): [4, 12],\n",
      " ('a', 'king'): [1, 12],\n",
      " ('a', 'man'): [1, 12],\n",
      " ('a', 'queen'): [1, 12],\n",
      " ('a', 'she'): [2, 12],\n",
      " ('a', 'woman'): [1, 12],\n",
      " ('berlin', 'germany'): [1, 2],\n",
      " ('berlin', 'is'): [1, 2],\n",
      " ('capital', 'france'): [1, 6],\n",
      " ('capital', 'germany'): [1, 6],\n",
      " ('capital', 'is'): [3, 6],\n",
      " ('capital', 'poland'): [1, 6],\n",
      " ('france', 'capital'): [1, 3],\n",
      " ('france', 'is'): [1, 3],\n",
      " ('france', 'paris'): [1, 3],\n",
      " ('germany', 'berlin'): [1, 3],\n",
      " ('germany', 'capital'): [1, 3],\n",
      " ('germany', 'is'): [1, 3],\n",
      " ('he', 'a'): [2, 4],\n",
      " ('he', 'is'): [2, 4],\n",
      " ('is', 'a'): [4, 21],\n",
      " ('is', 'berlin'): [1, 21],\n",
      " ('is', 'capital'): [3, 21],\n",
      " ('is', 'france'): [1, 21],\n",
      " ('is', 'germany'): [1, 21],\n",
      " ('is', 'he'): [2, 21],\n",
      " ('is', 'king'): [1, 21],\n",
      " ('is', 'man'): [1, 21],\n",
      " ('is', 'paris'): [1, 21],\n",
      " ('is', 'poland'): [1, 21],\n",
      " ('is', 'queen'): [1, 21],\n",
      " ('is', 'she'): [2, 21],\n",
      " ('is', 'warsaw'): [1, 21],\n",
      " ('is', 'woman'): [1, 21],\n",
      " ('king', 'a'): [1, 2],\n",
      " ('king', 'is'): [1, 2],\n",
      " ('man', 'a'): [1, 2],\n",
      " ('man', 'is'): [1, 2],\n",
      " ('paris', 'france'): [1, 2],\n",
      " ('paris', 'is'): [1, 2],\n",
      " ('poland', 'capital'): [1, 3],\n",
      " ('poland', 'is'): [1, 3],\n",
      " ('poland', 'warsaw'): [1, 3],\n",
      " ('queen', 'a'): [1, 2],\n",
      " ('queen', 'is'): [1, 2],\n",
      " ('she', 'a'): [2, 4],\n",
      " ('she', 'is'): [2, 4],\n",
      " ('warsaw', 'is'): [1, 2],\n",
      " ('warsaw', 'poland'): [1, 2],\n",
      " ('woman', 'a'): [1, 2],\n",
      " ('woman', 'is'): [1, 2]}\n",
      "{'he': 0, 'is': 1, 'a': 2, 'king': 3, 'she': 4, 'queen': 5, 'man': 6, 'woman': 7, 'warsaw': 8, 'poland': 9, 'capital': 10, 'berlin': 11, 'germany': 12, 'paris': 13, 'france': 14}\n",
      "{0: 'he', 1: 'is', 2: 'a', 3: 'king', 4: 'she', 5: 'queen', 6: 'man', 7: 'woman', 8: 'warsaw', 9: 'poland', 10: 'capital', 11: 'berlin', 12: 'germany', 13: 'paris', 14: 'france'}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pprint(corpus)\n",
    "\n",
    "    tokens = tokenize(corpus)\n",
    "    cc_pair = generate_center_context_pair(tokens, 2)\n",
    "    \n",
    "    word2idx = word2index(tokens)\n",
    "    idx2word = {key: val for (val, key) in word2idx.items()}\n",
    "\n",
    "    pprint(cc_pair)\n",
    "\n",
    "    # Making it global for debug purposes\n",
    "    global jdt\n",
    "    jdt = np.asarray(generate_jdt(cc_pair))\n",
    "    jdt = pd.DataFrame({'center': jdt[:, 0], 'context': jdt[:, 1]})\n",
    "    print(\"Joint Distribution Table\")\n",
    "    print(jdt[:10])\n",
    "\n",
    "    cc_pair_counts = all_p_of_context_given_center(jdt)\n",
    "    pprint(cc_pair_counts) \n",
    "    wordtoindex = word_to_index(tokens)\n",
    "    indextoword = index_to_word(tokens)\n",
    "    print(wordtoindex)\n",
    "    print(indextoword)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
